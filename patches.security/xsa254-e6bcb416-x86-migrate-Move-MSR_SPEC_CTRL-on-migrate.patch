From e6bcb416a5f5489366fc20f45fd92a703ad96e15 Mon Sep 17 00:00:00 2001
From: Andrew Cooper <andrew.cooper3@citrix.com>
Date: Thu, 8 Feb 2018 12:53:11 +0100
Subject: [PATCH] x86/migrate: Move MSR_SPEC_CTRL on migrate

Signed-off-by: Andrew Cooper <andrew.cooper3@citrix.com>
Reviewed-by: Wei Liu <wei.liu2@citrix.com>
Reviewed-by: Jan Beulich <jbeulich@suse.com>
master commit: 0cf2a4eb769302b7d7d7835540e7b2f15006df30
master date: 2018-01-26 14:10:21 +0000
---
 xen/arch/x86/domctl.c      | 31 +++++++++++++++++++++++++++++++
 xen/arch/x86/hvm/vmx/vmx.c | 23 +++++++++++++++++++++++
 2 files changed, 54 insertions(+)

diff --git a/xen/arch/x86/domctl.c b/xen/arch/x86/domctl.c
index 2b5cab27d2..7b2dddcf2a 100644
--- a/xen/arch/x86/domctl.c
+++ b/xen/arch/x86/domctl.c
@@ -1272,6 +1272,8 @@ long arch_do_domctl(
                 vmsrs->msr_count = nr_msrs;
             else
             {
+                uint32_t edx, dummy;
+
                 i = 0;
 
                 vcpu_pause(v);
@@ -1322,6 +1324,21 @@ long arch_do_domctl(
                     ++i;
                 }
 
+                domain_cpuid(d, 7, 0, &dummy, &dummy, &dummy, &edx);
+                if ( (edx & cpufeat_mask(X86_FEATURE_IBRSB)) &&
+                     v->arch.spec_ctrl )
+                {
+                    if ( i < vmsrs->msr_count && !ret )
+                    {
+                        msr.index = MSR_SPEC_CTRL;
+                        msr.reserved = 0;
+                        msr.value = v->arch.spec_ctrl;
+                        if ( copy_to_guest_offset(vmsrs->msrs, i, &msr, 1) )
+                            ret = -EFAULT;
+                    }
+                    ++i;
+                }
+
                 vcpu_unpause(v);
 
                 if ( i > vmsrs->msr_count && !ret )
@@ -1349,6 +1366,20 @@ long arch_do_domctl(
 
                 switch ( msr.index )
                 {
+                case MSR_SPEC_CTRL:
+                    if ( !boot_cpu_has(X86_FEATURE_IBRSB) )
+                        break; /* MSR available? */
+
+                    /*
+                     * Note: SPEC_CTRL_STIBP is specified as safe to use (i.e.
+                     * ignored) when STIBP isn't enumerated in hardware.
+                     */
+
+                    if ( msr.value & ~(SPEC_CTRL_IBRS | SPEC_CTRL_STIBP) )
+                        break;
+                    v->arch.spec_ctrl = msr.value;
+                    continue;
+
                 case MSR_INTEL_MISC_FEATURES_ENABLES:
                     v->arch.cpuid_faulting = !!(msr.value &
                                                 MSR_MISC_FEATURES_CPUID_FAULTING);
diff --git a/xen/arch/x86/hvm/vmx/vmx.c b/xen/arch/x86/hvm/vmx/vmx.c
index a7053527f1..e217a09bac 100644
--- a/xen/arch/x86/hvm/vmx/vmx.c
+++ b/xen/arch/x86/hvm/vmx/vmx.c
@@ -787,12 +787,15 @@ static int vmx_load_vmcs_ctxt(struct vcpu *v, struct hvm_hw_cpu *ctxt)
 static unsigned int __init vmx_init_msr(void)
 {
     return 1 /* MISC_FEATURES_ENABLES */ +
+           !!boot_cpu_has(X86_FEATURE_IBRSB) +
            (cpu_has_mpx && cpu_has_vmx_mpx) +
            (cpu_has_xsaves && cpu_has_vmx_xsaves);
 }
 
 static void vmx_save_msr(struct vcpu *v, struct hvm_msr *ctxt)
 {
+    uint32_t edx, dummy;
+
     vmx_vmcs_enter(v);
 
     if ( v->arch.cpuid_faulting )
@@ -801,6 +804,13 @@ static void vmx_save_msr(struct vcpu *v, struct hvm_msr *ctxt)
         ctxt->msr[ctxt->count++].val = MSR_MISC_FEATURES_CPUID_FAULTING;
     }
 
+    domain_cpuid(v->domain, 7, 0, &dummy, &dummy, &dummy, &edx);
+    if ( (edx & cpufeat_mask(X86_FEATURE_IBRSB)) && v->arch.spec_ctrl )
+    {
+        ctxt->msr[ctxt->count].index = MSR_SPEC_CTRL;
+        ctxt->msr[ctxt->count++].val = v->arch.spec_ctrl;
+    }
+
     if ( cpu_has_mpx && cpu_has_vmx_mpx )
     {
         __vmread(GUEST_BNDCFGS, &ctxt->msr[ctxt->count].val);
@@ -829,6 +839,19 @@ static int vmx_load_msr(struct vcpu *v, struct hvm_msr *ctxt)
     {
         switch ( ctxt->msr[i].index )
         {
+        case MSR_SPEC_CTRL:
+            if ( !boot_cpu_has(X86_FEATURE_IBRSB) )
+                err = -ENXIO; /* MSR available? */
+            /*
+             * Note: SPEC_CTRL_STIBP is specified as safe to use (i.e.
+             * ignored) when STIBP isn't enumerated in hardware.
+             */
+            else if ( ctxt->msr[i].val &
+                      ~(SPEC_CTRL_IBRS | SPEC_CTRL_STIBP) )
+                err = -ENXIO;
+            else
+                v->arch.spec_ctrl = ctxt->msr[i].val;
+            break;
         case MSR_INTEL_MISC_FEATURES_ENABLES:
             v->arch.cpuid_faulting = !!(ctxt->msr[i].val &
                                         MSR_MISC_FEATURES_CPUID_FAULTING);
-- 
2.16.1

